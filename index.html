<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yantao Lai</title>
  <link rel="icon" type="image/x-icon" href="resources/myicon.jpg">
  <meta name="author" content="Yantao Lai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yantao Lai (赖彦涛)</name>
              </p>
              <p>I am a final year master's student in the Computer Science and Technology College at Nanjing University of Aeronautics and Astronautics.
                During my master's studies, my thesis focuses on using vision-language representation learning and multimodal foundation models (e.g., multimodal LLMs) for modeling human visual attention (eye gaze). 
                Meanwhile, I have a strong interest in multiple research directions including Autonomous Driving, AIGC, and VLMs (Vision-Language Models). 
                <!-- , with a keen interest in the research of multimodal artificial intelligence, particularly the interaction between human attention and natural language. 
                My thesis focuses on exploring the dynamics shifts of human gaze/attention across various scenarios.  -->
                I am fortunate to be advised by <a href='https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm'>Rong Quan</a> (dissertation advisor), <a href='https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm'>Dong Liang</a>, <a href='http://faculty.nuaa.edu.cn/liwentong/zh_CN/index.htm'>Wentong Li</a>, and <a href='https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm'>Jie Qin</a>.</p>

              <p>Previously, I was an undergraduate student at the School of Internet at Anhui University, majoring in Intelligent Science and Technology, where I primarily studied foundational theories related to computer science and artificial intelligence.</p>

              <p style="text-align:center">
                <a href="resources/resume.pdf">Résumé</a> &nbsp/&nbsp
                <a href="mailto:yantaolai@nuaa.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com/citations?user=oKE2Wx8AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp -->
                <a href="resources/wechat.html">WeChat</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="resources/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="resources/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

	      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
            
  <li> <span style="color: red;"><strong>I am actively looking for full-time industry applied scientist / research scientist opportunities. Please contact me via <a href="mailto:yantaolai@nuaa.edu.cn">email</a> or <a href="resources/wechat.html">WeChat</a> if you have any leads. </strong></span></li>
  <li>[Oct 2025] I was awarded the National Scholarship for Postgraduates!
  <li>[Aug 2025] A <a href="https://pss-system.cponline.cnipa.gov.cn/documents/detail?prevPageTit=changgui">patent</a> related to Goal-Directed scanpath prediction has been granted!
  <li>[Aug 2025] One paper focused on Object Referring-Guided Scanpath Prediction has been submitted to AAAI 2026.
  <li>[May 2025] I have joined the Baidu Apollo, Beijing as a Autonomous Driving Perception Model Algorithm Intern!
  <li>[May 2025] One <a href="https://ieeexplore.ieee.org/document/10888383">paper</a> focused on Goal-Directed scanpath prediction has been accepted to ICASSP 2025 (Oral)!
  <li>[Apr 2025] A <a href="https://pss-system.cponline.cnipa.gov.cn/documents/detail?prevPageTit=changgui">patent</a> related to gaze prediction for panoramic images has been granted! </li>
  <li>[Dec 2024] I have joined the Xiaomi, Beijing as a Research Scientist Intern focusing on AIGC and large models!
  <li>[Oct 2024] One <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05104.pdf">paper</a> focused on gaze prediction for panoramic images has been accepted to ECCV 2024!
  </ul>
            </td>
          </tr>
        </tbody></table>
	      

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am broadly interested in Computer Vision, Autonomous Driving and Multimodal AI (AIGC, Vision-Language models). During my master's studies, my research primarily focuses on leveraging vision-language representation learning and multimodal foundation models (e.g., multimodal LLMs) for modeling human visual attention (eye gaze). For more details, refer to my <a href="resources/resume.pdf">résumé</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

		<!--  Pathformer3D -->
              <tr>
                <td style="padding:2%;width:25%;vertical-align:middle">
                  <img src='resources/pathformer3D.jpg' width="100%" height="auto">
                </td>
                <td style="padding:2%;width:75%;vertical-align:middle">
                  <papertitle>Pathformer3D: A 3D Scanpath Transformer for 360° Images</papertitle>
                  <br>
                  <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan*</a>,
                  <strong><span style="font-size: 15px">Yantao Lai*</span></strong>,
		              <a href="https://qmengyu.github.io/">Mengyu Qiu</a>,
		              <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang<sup>†</sup></a>
                  <br>
                  <em>ECCV, 2024 </em> <br>

			            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05104.pdf">PDF</a>
			            /
                  <a href="resources/Pathformer3D.html">Bibtex</a>
                  /
                  <a href="https://github.com/lsztzp/Pathformer3D">Code</a>
		              
                  <p></p>
                </td>
              </tr> 

		<!--  一种面向全景图像的人眼扫视轨迹预测方法 -->
    <tr>
      <td style="padding:2%;width:25%;vertical-align:middle">
        <img src='resources/pathformer3D_patent.jpg' width="100%" height="auto">
      </td>
      <td style="padding:2%;width:75%;vertical-align:middle">
        <papertitle>一种面向全景图像的人眼扫视轨迹预测方法</papertitle>
        <br>
        <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan</a>,
        <strong><span style="font-size: 15px">Yantao Lai</span></strong>,
        <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang</a>,
        <a href="https://qmengyu.github.io/">Mengyu Qiu</a>,
        <a href="https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm">Jie Qin</a>,
        <br>
        <em>Patent, Granted </em> <br>

        <a href="https://pss-system.cponline.cnipa.gov.cn/retrieveList?prevPageTit=changgui">PDF</a>
        /
        <a href="resources/Pathformer3D.html">Bibtex</a>
        /
        <a href="https://github.com/lsztzp/Pathformer3D">Code</a>
        
        <p></p>
      </td>
    </tr> 

    <!--  CLIPGaze -->
    <tr>
      <td style="padding:2%;width:25%;vertical-align:middle">
        <img src='resources/CLIPGaze.jpg' width="100%" height="auto">
      </td>
      <td style="padding:2%;width:75%;vertical-align:middle">
        <papertitle>CLIPGaze: Zero-Shot Goal-Directed Scanpath Prediction Using CLIP</papertitle>
        <br>
        <strong><span style="font-size: 15px">Yantao Lai</span></strong>,
        <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan</a>,
        <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang<sup>†</sup></a>,
        <a href="https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm">Jie Qin</a>,
        <br>
        <em>ICASSP oral, 2025 </em> <br>

        <a href="https://ieeexplore.ieee.org/document/10888383">PDF</a>
        /
        <a href="resources/CLIPGaze.html">Bibtex</a>
        /
        <a href="https://github.com/lsztzp/CLIPGaze">Code</a>
        
        <p></p>
      </td>
    </tr> 

    <!--  一种目标导向的扫视路径预测方法 -->
    <tr>
      <td style="padding:2%;width:25%;vertical-align:middle">
        <img src='resources/CLIPGaze_patent.jpg' width="100%" height="auto">
      </td>
      <td style="padding:2%;width:75%;vertical-align:middle">
        <papertitle>一种目标导向的扫视路径预测方法</papertitle>
        <br>
        <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan</a>,
        <strong><span style="font-size: 15px">Yantao Lai</span></strong>,
        <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang</a>,
        <a href="https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm">Jie Qin</a>,
        <br>
        <em>Patent, Disclosed </em> <br>

        <a href="https://pss-system.cponline.cnipa.gov.cn/retrieveList?prevPageTit=changgui">PDF</a>
        /
        <a href="resources/CLIPGaze.html">Bibtex</a>
        /
        <a href="https://github.com/lsztzp/CLIPGaze">Code</a>
        
        <p></p>
      </td>
    </tr> 



    <!--  Other -->
    


           </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="1">
                    <a href="https://jonbarron.info/">Webpage template from Jon Barron</a>
                  </font>
                </p>
              </td>
            </tr>
    </tbody>
  </table>
				

      </td>
    </tr>
  </table>
</body>

</html>
