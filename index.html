<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yantao Lai</title>
  <link rel="icon" type="image/x-icon" href="resources/myicon.jpg">
  <meta name="author" content="Yantao Lai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yantao Lai</name>
              </p>
              <p>I am a second year master's student in the Computer Science and Technology College at Nanjing University of Aeronautics and Astronautics, with a keen interest in the research of multimodal artificial intelligence, particularly the interaction between human attention and natural language. My thesis focuses on exploring the dynamics shifts of human gaze/attention across various scenarios. I am fortunate to be advised by <a href='https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm'>Rong Quan</a> (dissertation advisor), <a href='https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm'>Dong Liang</a>, and <a href='https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm'>Jie Qin</a>.</p>

              <p>Previously, I was an undergraduate student at the School of Internet at Anhui University, majoring in Intelligent Science and Technology, where I primarily studied foundational theories related to computer science and artificial intelligence.</p>

              <p style="text-align:center">
                <a href="resources/resume.pdf">Résumé</a> &nbsp/&nbsp
                <a href="mailto:yantaolai@nuaa.edu.cn">Email</a> &nbsp/&nbsp
                <!-- <a href="https://scholar.google.com/citations?user=oKE2Wx8AAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp -->
                <a href="resources/wechat.html">WeChat</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="resources/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="resources/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

	      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
  <li>[Feb 2025] A <a href="https://pss-system.cponline.cnipa.gov.cn/documents/detail?prevPageTit=changgui">patent</a> related to gaze prediction for panoramic images has been granted! </li>
  <li>[Dec 2024] One paper focused on Goal-Directed scanpath prediction has been accepted to ICASSP 2025!
  <li>[Oct 2024] A patent related to Goal-Directed scanpath prediction has been submit.
  <li>[Oct 2024] One <a href="https://arxiv.org/abs/2407.10563">paper</a> focused on gaze prediction for panoramic images has been accepted to ECCV 2024!
  </ul>
            </td>
          </tr>
        </tbody></table>
	      

	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am broadly interested in Computer Vision and Multimodal AI (Vision-Language Modeling). My primary research focus is on modeling human attention in multimodal scenes through the prediction of human gaze. For more details, refer to my <a href="resources/resume.pdf">résumé</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

		<!--  Pathformer3D -->
              <tr>
                <td style="padding:2%;width:25%;vertical-align:middle">
                  <img src='resources/pathformer3D.jpg' width="100%" height="auto">
                </td>
                <td style="padding:2%;width:75%;vertical-align:middle">
                  <papertitle>Pathformer3D: A 3D Scanpath Transformer for 360° Images</papertitle>
                  <br>
                  <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan*</a>,
                  <strong><span style="font-size: 15px">Yantao Lai*</span></strong>,
		              <a href="https://qmengyu.github.io/">Mengyu Qiu</a>,
		              <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang<sup>†</sup></a>
                  <br>
                  <em>ECCV, 2024 </em> <br>

			            <a href="https://arxiv.org/abs/2407.10563">PDF</a>
			            /
                  <a href="https://dongl-group.github.io/bibtex/Pathformer3D.html">Bibtex</a>
                  /
                  <a href="https://github.com/lsztzp/Pathformer3D">Code</a>
		              
                  <p></p>
                </td>
              </tr> 

		<!--  一种面向全景图像的人眼扫视轨迹预测方法 -->
    <tr>
      <td style="padding:2%;width:25%;vertical-align:middle">
        <img src='resources/pathformer3D_patent.jpg' width="100%" height="auto">
      </td>
      <td style="padding:2%;width:75%;vertical-align:middle">
        <papertitle>一种面向全景图像的人眼扫视轨迹预测方法</papertitle>
        <br>
        <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan</a>,
        <strong><span style="font-size: 15px">Yantao Lai</span></strong>,
        <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang</a>,
        <a href="https://qmengyu.github.io/">Mengyu Qiu</a>,
        <a href="https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm">Jie Qin</a>,
        <br>
        <em>Patent, Granted </em> <br>

        <a href="https://pss-system.cponline.cnipa.gov.cn/documents/detail?prevPageTit=changgui">PDF</a>
        /
        <a href="https://dongl-group.github.io/bibtex/Pathformer3D.html">Bibtex</a>
        /
        <a href="https://github.com/lsztzp/Pathformer3D">Code</a>
        
        <p></p>
      </td>
    </tr> 

    <!--  CLIPGaze -->
    <tr>
      <td style="padding:2%;width:25%;vertical-align:middle">
        <img src='resources/CLIPGaze.jpg' width="100%" height="auto">
      </td>
      <td style="padding:2%;width:75%;vertical-align:middle">
        <papertitle>CLIPGaze: Zero-Shot Goal-Directed Scanpath Prediction Using CLIP</papertitle>
        <br>
        <strong><span style="font-size: 15px">Yantao Lai</span></strong>,
        <a href="https://faculty.nuaa.edu.cn/quanrong/zh_CN/index.htm">Rong Quan</a>,
        <a href="https://faculty.nuaa.edu.cn/liangdong/zh_CN/index.htm">Dong Liang<sup>†</sup></a>,
        <a href="https://faculty.nuaa.edu.cn/qinjie/zh_CN/index.htm">Jie Qin</a>,
        <br>
        <em>ICASSP, 2025 </em> <br>

        <a href="https://ieeexplore.ieee.org/document/10888383">PDF</a>
        /
        <a href="https://dongl-group.github.io/bibtex/Pathformer3D.html">Bibtex</a>
        /
        <a href="https://github.com/lsztzp/CLIPGaze">Code</a>
        
        <p></p>
      </td>
    </tr> 



    <!--  Other -->
    


           </tbody></table>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td>
                <br>
                <p align="right">
                  <font size="1">
                    <a href="https://jonbarron.info/">Webpage template from Jon Barron</a>
                  </font>
                </p>
              </td>
            </tr>
    </tbody>
  </table>
				

      </td>
    </tr>
  </table>
</body>

</html>
